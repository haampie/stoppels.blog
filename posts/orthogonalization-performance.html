<!doctype html> <html lang="en"> <head> <meta charset="utf-8"> <meta http-equiv="x-ua-compatible" content="ie=edge"> <title>Orthogonalization performance | Harmen Stoppels</title> <meta name="description" content="Methods like GMRES and Jacobi-Davidson construct an orthogonal basis for their search subspace. It is well-known that classical Gram-Schmidt (CGS) is vulnerable for loss of orthogonality due to rounding errors. Modified Gram-Schmidt (MGS) is usually the fix for this, yet it is not free of rounding errors and is memory-bound when it comes to performance. In this post we'll look into iterative or refined orthogonalization methods and their performance."> <meta name="viewport" content="width=device-width, initial-scale=1"> <meta property="og:title" content="Orthogonalization performance"> <meta property="og:type" content="website"> <meta property="og:url" content="http://stoppels.blog/posts/orthogonalization-performance"> <meta property="og:description" content="Methods like GMRES and Jacobi-Davidson construct an orthogonal basis for their search subspace. It is well-known that classical Gram-Schmidt (CGS) is vulnerable for loss of orthogonality due to rounding errors. Modified Gram-Schmidt (MGS) is usually the fix for this, yet it is not free of rounding errors and is memory-bound when it comes to performance. In this post we'll look into iterative or refined orthogonalization methods and their performance."> <meta property="og:site_name" content="Harmen Stoppels"> <meta property="og:image" content="http://stoppels.blog/assets/logo-c03d5362cd6e2bf1b8be92b4c0763645311d085017850c7fe3a832d334768232.png"> <meta property="og:image:type" content="image/png"> <meta property="og:image:width" content="1200"> <meta property="og:image:height" content="630"> <meta name="twitter:card" content="summary"> <meta name="twitter:url" content="http://stoppels.blog/posts/orthogonalization-performance"> <meta name="twitter:title" content="Orthogonalization performance"> <meta name="twitter:description" content="Methods like GMRES and Jacobi-Davidson construct an orthogonal basis for their search subspace. It is well-known that classical Gram-Schmidt (CGS) is vulnerable for loss of orthogonality due to rounding errors. Modified Gram-Schmidt (MGS) is usually the fix for this, yet it is not free of rounding errors and is memory-bound when it comes to performance. In this post we'll look into iterative or refined orthogonalization methods and their performance."> <meta name="twitter:image" content="http://stoppels.blog/assets/logo-c03d5362cd6e2bf1b8be92b4c0763645311d085017850c7fe3a832d334768232.png"> <link rel="apple-touch-icon" href="/assets/touch-icon-5fb2a3f5fa8c8d82a463d456ac78e3d475ee9c0803f7a91f875fd8fa0a763100.png"> <link href="http://stoppels.blog/feed.xml" type="application/rss+xml" rel="alternate" title="Harmen Stoppels Last 10 blog posts"/> <style>html{font-family:sans-serif;line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,footer,header,nav{display:block}h1{font-size:2em;margin:0.67em 0}figure,main{display:block}figure{margin:1em 40px}pre{font-family:monospace, monospace;font-size:1em}a{background-color:transparent;-webkit-text-decoration-skip:objects}a:active,a:hover{outline-width:0}code{font-family:monospace, monospace;font-size:1em}svg:not(:root){overflow:hidden}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}*,*::before,*::after{-webkit-box-sizing:border-box;box-sizing:border-box}html{font-size:16px}body{margin:0 auto;font-family:Arial, Helvetica, sans-serif;-webkit-font-smoothing:antialiased;font-weight:400;line-height:1.8;color:#615b5b;background:#fff1e0}p{margin:0;font-weight:400}h1,h2,h3{margin:0;line-height:1.5;text-rendering:optimizeLegibility}h1{font-size:25.6px;font-weight:400;letter-spacing:-.03em;color:#121111}h2{font-size:24px;font-weight:400}h3{font-size:20.8px;font-weight:500}@media all and (max-width: 767px){h1{font-size:24px}h2{font-size:21.6px}h3{font-size:20px}}a{color:#615b5b;text-decoration:underline;-webkit-transition:color 0.2s linear;transition:color 0.2s linear}a:hover,a:active{color:#393636}a:focus{color:#393636;outline:none}ul{padding-left:40px;margin:0}::-moz-selection{color:#fff;background-color:#121111}::selection{color:#fff;background-color:#121111}.footer{display:block;padding:35px 0 85px;border-top:1px solid rgba(0,0,0,0.1)}.footer p{font-size:15px;color:#ada8a8}.grid{display:block;padding:0;margin:0 -20px;font-size:0;text-align:left}.grid-cell{display:inline-block;width:100%;padding:0 20px;margin:0;font-size:16px;text-align:left;vertical-align:top}.grid-centered{max-width:650px;margin-right:auto;margin-left:auto}.article{display:block;margin:100px 0}.article-list-footer{display:block}.article-list-footer span,.article-list-footer a{display:inline-block;font-size:12px;color:#888181;text-transform:uppercase;vertical-align:middle}.article-list-footer a{margin-right:7.5px;color:#615b5b}.article-list-footer a:hover{color:#121111}.article-list-footer a:last-child{margin-right:0}.article-list-divider{margin:0 15px}.article-list-tags{display:inline-block;vertical-align:top}.article-header{display:block;padding-bottom:30px;margin-bottom:30px;border-bottom:1px solid rgba(0,0,0,0.1)}.article-header p{display:block;margin:12px 0 10px;font-size:15px;color:#615b5b}.article-header a{text-decoration:none}.article-content{display:block}.article-content p{display:block;margin-bottom:30px}.article-content h2,.article-content h3{display:block;margin-bottom:10px;font-family:Arial, Helvetica, sans-serif;color:#121111}.article-share{display:block;margin-top:-4px}.article-share a{display:inline-block;margin-right:12px;vertical-align:middle}.article-share a svg{vertical-align:middle;-webkit-transition:fill 0.2s linear;transition:fill 0.2s linear;fill:#ada8a8}.article-share a:hover svg{fill:#615b5b}@media all and (max-width: 767px){.article-list-footer{display:block}.article-list-divider:last-of-type{display:none}.article-list-tags{display:block;margin-top:-7px}}.header-nav{display:block;padding:75px 0 20px;border-bottom:1px solid rgba(0,0,0,0.1)}.header-logo{display:inline-block;font-family:"Palatino Linotype", "Book Antiqua", Palatino, serif;font-size:36px;font-weight:700;color:#000;text-decoration:none}.header-links{float:right;padding:0;margin:15px 0 0;list-style:none}.header-links li{display:inline-block;margin-left:20px;vertical-align:middle}.header-links li:first-child{margin-left:0}.header-links li a{font-size:18px;color:#393636}.header-links li a:hover{color:#121111}@media all and (max-width: 415px){.header-nav{text-align:center}.header-links{display:block;float:none;text-align:center}.header-links li{margin:0 10px}.header-links li:last-child{margin-right:0}}.highlight{padding:50px;margin:0;margin:30px 0;overflow:auto;font-weight:400;background:#f3dec8;-webkit-box-shadow:0 2px 0.2px rgba(0,0,0,0.1);box-shadow:0 2px 0.2px rgba(0,0,0,0.1)}.highlight pre{margin:0}.highlighter-rouge{padding:2px 4px;font-size:14px;background:#f3dec8;border:1px solid rgba(0,0,0,0.1);border-radius:1px}@media all and (max-width: 767px){.highlight{padding:50px 25px;font-size:14px}}.highlight .c{font-style:italic;color:#998}.highlight .k{font-weight:bold}.highlight .o{font-weight:bold}.highlight .s{color:#d14}.highlight .nf{font-weight:bold;color:#900}.highlight .mi{color:#099}.highlight .sc{color:#d14}.icon{display:inline-block;width:1em;height:1em;stroke-width:0;stroke:currentColor;fill:currentColor}.icon-ion-social-rss{width:0.75em}.icon-ion-android-person{width:0.75em}</style> <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css"> </head> <body> <main role="main"> <div class="grid grid-centered"> <div class="grid-cell"> <nav class="header-nav reveal"> <a href="/" class="header-logo" title="Harmen Stoppels">Harmen Stoppels</a> <ul class="header-links"> <li> <a href="/about" title="About me"> <svg class="icon icon-ion-android-person"><use xlink:href="#icon-ion-android-person"></use></svg> </a> </li> <li> <a href="/feed.xml" target="_blank" title="RSS"> <svg class="icon icon-ion-social-rss"><use xlink:href="#icon-ion-social-rss"></use></svg> </a> </li> </ul> </nav> <article class="article reveal"> <header class="article-header"> <h1>Orthogonalization performance</h1> <p>Methods like GMRES and Jacobi-Davidson construct an orthogonal basis for their search subspace. It is well-known that classical Gram-Schmidt (CGS) is vulnerable for loss of orthogonality due to rounding errors. Modified Gram-Schmidt (MGS) is usually the fix for this, yet it is not free of rounding errors and is memory-bound when it comes to performance. In this post we'll look into iterative or refined orthogonalization methods and their performance.</p> <div class="article-list-footer"> <span class="article-list-date"> June 18, 2017 </span> <span class="article-list-divider">-</span> <span class="article-list-minutes"> 10 minute read </span> <span class="article-list-divider">-</span> <div class="article-list-tags"> <a href="/tag/gsoc">gsoc</a> <a href="/tag/julia">julia</a> </div> </div> </header> <div class="article-content"> <p>In GMRES it is necessary to build an orthonormal basis for the Krylov subspace, because the basis vectors <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>v</mi><mo separator="true">,</mo><mi>A</mi><mi>v</mi><mo separator="true">,</mo><msup><mi>A</mi><mn>2</mn></msup><mi>v</mi><mo separator="true">,</mo><mo>⋯</mo></mrow><annotation encoding="application/x-tex">v, Av, A^2v, \cdots</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:1.008548em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">v</span><span class="mpunct">,</span><span class="mord mathit">A</span><span class="mord mathit" style="margin-right:0.03588em;">v</span><span class="mpunct">,</span><span class="mord"><span class="mord mathit">A</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit" style="margin-right:0.03588em;">v</span><span class="mpunct">,</span><span class="minner">⋯</span></span></span></span> become quickly linearly dependent in finite precision. In Jacobi-Davidson we require orthonormality of the search subspace and the converged Schur vectors as well, so that converged Schur vector do not re-enter the search subspace. Also, throughout both algorithms we simplify expressions via equalities like <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>V</mi><mo>∗</mo></msup><mi>V</mi><mo>=</mo><mi>I</mi></mrow><annotation encoding="application/x-tex">V^*V = I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.688696em;"></span><span class="strut bottom" style="height:0.688696em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.22222em;">V</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord">∗</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit" style="margin-right:0.22222em;">V</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.07847em;">I</span></span></span></span>. Due to rounding errors this identity might however not hold exactly. Therefore it is important to have some guarantee of orthogonality.</p> <p>The benchmarks in this post are performed on an Intel i5-4460 @ 3.20GHz using 16GB of DDR3 memory at 1600MHz.</p> <h2 id="classical-and-modified-gram-schmidt">Classical and Modified Gram-Schmidt</h2> <p>Given a matrix <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>V</mi><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">C</mi></mrow><mrow><mi>n</mi><mo>×</mo><mi>m</mi></mrow></msup></mrow><annotation encoding="application/x-tex">V \in \mathbb{C}^{n \times m}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.771331em;"></span><span class="strut bottom" style="height:0.810431em;vertical-align:-0.0391em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.22222em;">V</span><span class="mrel">∈</span><span class=""><span class="mord textstyle uncramped"><span class="mord mathbb">C</span></span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit">n</span><span class="mbin">×</span><span class="mord mathit">m</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> where <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi><mo>≫</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">n \gg m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.5391em;"></span><span class="strut bottom" style="height:0.5782em;vertical-align:-0.0391em;"></span><span class="base textstyle uncramped"><span class="mord mathit">n</span><span class="mrel">≫</span><span class="mord mathit">m</span></span></span></span> and a vector <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">C</mi></mrow><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">w \in \mathbb{C}^n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68889em;"></span><span class="strut bottom" style="height:0.72799em;vertical-align:-0.0391em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mrel">∈</span><span class=""><span class="mord textstyle uncramped"><span class="mord mathbb">C</span></span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit">n</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>, our goal is to remove the components of <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02691em;">w</span></span></span></span> spanned by the columns of <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.22222em;">V</span></span></span></span>.</p> <p>This comes down to updating <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo>:</mo><mo>=</mo><mo>(</mo><mi>I</mi><mo>−</mo><mi>V</mi><msup><mi>V</mi><mo>∗</mo></msup><mo>)</mo><mi>w</mi></mrow><annotation encoding="application/x-tex">w := (I - VV^*)w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mrel">:</span><span class="mrel">=</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.07847em;">I</span><span class="mbin">−</span><span class="mord mathit" style="margin-right:0.22222em;">V</span><span class="mord"><span class="mord mathit" style="margin-right:0.22222em;">V</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord">∗</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span><span class="mord mathit" style="margin-right:0.02691em;">w</span></span></span></span> and subsequently normalizing <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo>:</mo><mo>=</mo><mi>w</mi><mi mathvariant="normal">/</mi><mi mathvariant="normal">∥</mi><mi>w</mi><mi mathvariant="normal">∥</mi></mrow><annotation encoding="application/x-tex">w := w / \|w\|</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mrel">:</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mord mathrm">/</span><span class="mord mathrm">∥</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mord mathrm">∥</span></span></span></span>. In GMRES we want to store the projection <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>V</mi><mo>∗</mo></msup><mi>w</mi></mrow><annotation encoding="application/x-tex">V^*w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.688696em;"></span><span class="strut bottom" style="height:0.688696em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.22222em;">V</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord">∗</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit" style="margin-right:0.02691em;">w</span></span></span></span> as well.</p> <p>Classical Gram-Schmidt in Julia would look like this:</p> <figure class="highlight"><pre><code class="language-julia" data-lang="julia"><span class="k">import</span> <span class="n">Base</span><span class="o">.</span><span class="n">LinAlg</span><span class="o">.</span><span class="n">BLAS</span><span class="x">:</span> <span class="n">gemv!</span><span class="x">,</span> <span class="n">gemv</span>

<span class="k">function</span><span class="nf"> classical_gram_schmidt</span><span class="o">!</span><span class="x">{</span><span class="n">T</span><span class="x">}(</span><span class="n">V</span><span class="o">::</span><span class="n">StridedMatrix</span><span class="x">{</span><span class="n">T</span><span class="x">},</span> <span class="n">w</span><span class="o">::</span><span class="n">StridedVector</span><span class="x">{</span><span class="n">T</span><span class="x">})</span>
    
    <span class="c"># Orthogonalize</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">gemv</span><span class="x">(</span><span class="sc">'T'</span><span class="x">,</span> <span class="n">one</span><span class="x">(</span><span class="n">T</span><span class="x">),</span> <span class="n">V</span><span class="x">,</span> <span class="n">w</span><span class="x">)</span>
    <span class="n">gemv!</span><span class="x">(</span><span class="sc">'N'</span><span class="x">,</span> <span class="o">-</span><span class="n">one</span><span class="x">(</span><span class="n">T</span><span class="x">),</span> <span class="n">V</span><span class="x">,</span> <span class="n">h</span><span class="x">,</span> <span class="n">one</span><span class="x">(</span><span class="n">T</span><span class="x">),</span> <span class="n">w</span><span class="x">)</span>

    <span class="c"># Normalize</span>
    <span class="n">nrm</span> <span class="o">=</span> <span class="n">norm</span><span class="x">(</span><span class="n">w</span><span class="x">)</span>
    <span class="n">scale!</span><span class="x">(</span><span class="n">w</span><span class="x">,</span> <span class="n">one</span><span class="x">(</span><span class="n">T</span><span class="x">)</span> <span class="o">/</span> <span class="n">nrm</span><span class="x">)</span>

    <span class="n">h</span><span class="x">,</span> <span class="n">nrm</span>
<span class="k">end</span></code></pre></figure> <p>It is well-known that due to rounding errors the above procedure is not stable. Modified Gram-Schmidt tries to “solve” this problem by performing the projection sequentially:</p> <figure class="highlight"><pre><code class="language-julia" data-lang="julia"><span class="k">import</span> <span class="n">Base</span><span class="o">.</span><span class="n">LinAlg</span><span class="o">.</span><span class="n">BLAS</span><span class="x">:</span> <span class="n">axpy!</span>

<span class="k">function</span><span class="nf"> modified_gram_schmidt</span><span class="o">!</span><span class="x">{</span><span class="n">T</span><span class="x">}(</span><span class="n">V</span><span class="o">::</span><span class="n">StridedMatrix</span><span class="x">{</span><span class="n">T</span><span class="x">},</span> <span class="n">w</span><span class="o">::</span><span class="n">StridedVector</span><span class="x">{</span><span class="n">T</span><span class="x">})</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">size</span><span class="x">(</span><span class="n">V</span><span class="x">,</span> <span class="mi">2</span><span class="x">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">zeros</span><span class="x">(</span><span class="n">T</span><span class="x">,</span> <span class="n">k</span><span class="x">)</span>

    <span class="c"># Orthogonalize</span>
    <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span> <span class="x">:</span> <span class="n">k</span>
        <span class="n">column</span> <span class="o">=</span> <span class="nd">@view</span><span class="x">(</span><span class="n">V</span><span class="x">[:,</span> <span class="n">i</span><span class="x">])</span>
        <span class="n">h</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">=</span> <span class="n">dot</span><span class="x">(</span><span class="n">column</span><span class="x">,</span> <span class="n">w</span><span class="x">)</span>
        <span class="n">axpy!</span><span class="x">(</span><span class="o">-</span><span class="n">h</span><span class="x">[</span><span class="n">i</span><span class="x">],</span> <span class="n">column</span><span class="x">,</span> <span class="n">w</span><span class="x">)</span>
    <span class="k">end</span>

    <span class="c"># Normalize</span>
    <span class="n">nrm</span> <span class="o">=</span> <span class="n">norm</span><span class="x">(</span><span class="n">w</span><span class="x">)</span>
    <span class="n">scale!</span><span class="x">(</span><span class="n">w</span><span class="x">,</span> <span class="n">one</span><span class="x">(</span><span class="n">T</span><span class="x">)</span> <span class="o">/</span> <span class="n">nrm</span><span class="x">)</span>

    <span class="n">h</span><span class="x">,</span> <span class="n">nrm</span>
<span class="k">end</span></code></pre></figure> <p>Performance-wise this for-loop is a major bottleneck. The problem is that we have gone from BLAS-2 (matrix-vector product) to BLAS-1 (inner products).</p> <p>If we bench the above with <code class="highlighter-rouge">m = 20</code> and <code class="highlighter-rouge">n = 10_000_000</code> we’ll quickly see the problem:</p> <figure class="highlight"><pre><code class="language-julia" data-lang="julia"><span class="n">using</span> <span class="n">BenchmarkTools</span>

<span class="k">function</span><span class="nf"> bench</span><span class="x">(;</span> <span class="n">m</span> <span class="o">=</span> <span class="mi">20</span><span class="x">)</span>
    <span class="n">srand</span><span class="x">(</span><span class="mi">1</span><span class="x">)</span>
    
    <span class="n">suite</span> <span class="o">=</span> <span class="n">BenchmarkGroup</span><span class="x">()</span>
    
    <span class="k">for</span> <span class="n">threads</span> <span class="o">=</span> <span class="x">[</span><span class="mi">1</span><span class="x">,</span> <span class="mi">2</span><span class="x">,</span> <span class="mi">4</span><span class="x">]</span>
        <span class="n">BLAS</span><span class="o">.</span><span class="n">set_num_threads</span><span class="x">(</span><span class="n">threads</span><span class="x">)</span>
        <span class="n">thread_key</span> <span class="o">=</span> <span class="n">string</span><span class="x">(</span><span class="n">threads</span><span class="x">)</span>
        <span class="n">suite</span><span class="x">[</span><span class="n">thread_key</span><span class="x">]</span> <span class="o">=</span> <span class="n">BenchmarkGroup</span><span class="x">()</span>
        <span class="k">for</span> <span class="n">n</span> <span class="o">=</span> <span class="x">[</span><span class="mi">1_000_000</span><span class="x">,</span> <span class="mi">10_000_000</span><span class="x">]</span>
            <span class="n">V</span><span class="x">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">qr</span><span class="x">(</span><span class="n">rand</span><span class="x">(</span><span class="n">n</span><span class="x">,</span> <span class="n">m</span><span class="x">))</span>
            <span class="n">new_vec</span> <span class="o">=</span> <span class="n">rand</span><span class="x">(</span><span class="n">n</span><span class="x">)</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">string</span><span class="x">(</span><span class="n">n</span><span class="x">)</span>
            <span class="n">suite</span><span class="x">[</span><span class="n">thread_key</span><span class="x">][</span><span class="n">key</span><span class="x">]</span> <span class="o">=</span> <span class="n">BenchmarkGroup</span><span class="x">()</span>
            <span class="n">suite</span><span class="x">[</span><span class="n">thread_key</span><span class="x">][</span><span class="n">key</span><span class="x">][</span><span class="s">"cgs"</span><span class="x">]</span> <span class="o">=</span> <span class="nd">@benchmark</span> <span class="n">classical_gram_schmidt!</span><span class="x">(</span><span class="o">$</span><span class="n">V</span><span class="x">,</span> <span class="n">a</span><span class="x">)</span> <span class="n">setup</span><span class="o">=</span><span class="x">(</span><span class="n">a</span> <span class="o">=</span> <span class="n">copy</span><span class="x">(</span><span class="o">$</span><span class="n">new_vec</span><span class="x">))</span>
            <span class="n">suite</span><span class="x">[</span><span class="n">thread_key</span><span class="x">][</span><span class="n">key</span><span class="x">][</span><span class="s">"mgs"</span><span class="x">]</span> <span class="o">=</span> <span class="nd">@benchmark</span> <span class="n">modified_gram_schmidt!</span><span class="x">(</span><span class="o">$</span><span class="n">V</span><span class="x">,</span> <span class="n">a</span><span class="x">)</span> <span class="n">setup</span><span class="o">=</span><span class="x">(</span><span class="n">a</span> <span class="o">=</span> <span class="n">copy</span><span class="x">(</span><span class="o">$</span><span class="n">new_vec</span><span class="x">))</span>
        <span class="k">end</span>
    <span class="k">end</span>

    <span class="n">suite</span>
<span class="k">end</span></code></pre></figure> <p>This outputs:</p> <figure class="highlight"><pre><code class="language-text" data-lang="text">  "1" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
          "1000000" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
                  "mgs" =&gt; Trial(39.492 ms)
                  "cgs" =&gt; Trial(19.027 ms)
          "10000000" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
                  "mgs" =&gt; Trial(414.534 ms)
                  "cgs" =&gt; Trial(199.866 ms)
  "2" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
          "1000000" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
                  "mgs" =&gt; Trial(35.880 ms)
                  "cgs" =&gt; Trial(16.462 ms)
          "10000000" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
                  "mgs" =&gt; Trial(393.617 ms)
                  "cgs" =&gt; Trial(168.942 ms)
  "4" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
          "1000000" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
                  "mgs" =&gt; Trial(35.084 ms)
                  "cgs" =&gt; Trial(15.886 ms)
          "10000000" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
                  "mgs" =&gt; Trial(392.145 ms)
                  "cgs" =&gt; Trial(159.393 ms)</code></pre></figure> <p>which shows that MGS is more than twice as slow. The reason for this is that BLAS-1 is memory bound: all data is touched only once, and there is a lot of data in memory. For this reason it is almost useless to have threading enabled.</p> <h2 id="iterative--refined-orthogonalization">Iterative / refined orthogonalization</h2> <p>Even though MGS is an easy trick to ensure better orthogonality, it does not necessarily generate vectors that are orthogonal up to machine precision. For instance, if we do</p> <figure class="highlight"><pre><code class="language-text" data-lang="text">srand(1)
V, _ = qr(rand(1_000_000, 10))
w = rand(1_000_000)
modified_gram_schmidt!(V, w)
@show norm(V' * w)
modified_gram_schmidt!(V, w)
@show norm(V' * w)</code></pre></figure> <p>it outputs</p> <figure class="highlight"><pre><code class="language-text" data-lang="text">norm(V' * w) = 1.0289082309190917e-15
norm(V' * w) = 4.513770868406318e-17</code></pre></figure> <p>which basically means that the projection is not idempotent. After the first pass of MGS there are still components in the direction of <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.22222em;">V</span></span></span></span> and only in the second pass these are removed almost up to machine precision.</p> <p>If we really need to maintain orthogonality, one idea is to repeat MGS twice or even more. In Krylov subspace there is the rule of thumb that “twice is enough” due to Kahan and Parlett, but we can just as well decide whether to repeat orthogonalization by using the Daniel-Gragg-Kaufman-Stewart criterion. This criterion states that we should repeat orthogonalization if the tangent between <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02691em;">w</span></span></span></span> and <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>s</mi><mi>p</mi><mi>a</mi><mi>n</mi><mo>(</mo><mi>V</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">span(V)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">s</span><span class="mord mathit">p</span><span class="mord mathit">a</span><span class="mord mathit">n</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.22222em;">V</span><span class="mclose">)</span></span></span></span> is smaller than <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>η</mi></mrow><annotation encoding="application/x-tex">\eta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">η</span></span></span></span>. In ARPACK it seems that this parameter is chosen <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>η</mi><mo>=</mo><mn>1</mn><mi mathvariant="normal">/</mi><msqrt><mrow><mn>2</mn></mrow></msqrt></mrow><annotation encoding="application/x-tex">\eta = 1 / \sqrt{2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.9072200000000001em;"></span><span class="strut bottom" style="height:1.1572200000000001em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">η</span><span class="mrel">=</span><span class="mord mathrm">1</span><span class="mord mathrm">/</span><span class="sqrt mord"><span class="sqrt-sign" style="top:-0.06722000000000006em;"><span class="style-wrap reset-textstyle textstyle uncramped">√</span></span><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="mord textstyle cramped"><span class="mord mathrm">2</span></span></span><span style="top:-0.8272200000000001em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped sqrt-line"></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span></span></span></span>.</p> <p>I’m going to assume reorthogonalization is only necessary once, but the <code class="highlighter-rouge">if</code> can be replaced by a <code class="highlighter-rouge">while</code>.</p> <figure class="highlight"><pre><code class="language-julia" data-lang="julia"><span class="k">function</span><span class="nf"> repeated_classical_gram_schmidt</span><span class="o">!</span><span class="x">{</span><span class="n">T</span><span class="x">}(</span><span class="n">V</span><span class="o">::</span><span class="n">StridedMatrix</span><span class="x">{</span><span class="n">T</span><span class="x">},</span> <span class="n">w</span><span class="o">::</span><span class="n">StridedVector</span><span class="x">{</span><span class="n">T</span><span class="x">};</span> <span class="n">η</span> <span class="o">=</span> <span class="n">one</span><span class="x">(</span><span class="n">T</span><span class="x">)</span> <span class="o">/</span> <span class="n">√2</span><span class="x">)</span>
    
    <span class="c"># Orthogonalize</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">gemv</span><span class="x">(</span><span class="sc">'T'</span><span class="x">,</span> <span class="n">one</span><span class="x">(</span><span class="n">T</span><span class="x">),</span> <span class="n">V</span><span class="x">,</span> <span class="n">w</span><span class="x">)</span>
    <span class="n">gemv!</span><span class="x">(</span><span class="sc">'N'</span><span class="x">,</span> <span class="o">-</span><span class="n">one</span><span class="x">(</span><span class="n">T</span><span class="x">),</span> <span class="n">V</span><span class="x">,</span> <span class="n">h</span><span class="x">,</span> <span class="n">one</span><span class="x">(</span><span class="n">T</span><span class="x">),</span> <span class="n">w</span><span class="x">)</span>

    <span class="c"># Repeat</span>
    <span class="n">nrm</span> <span class="o">=</span> <span class="n">norm</span><span class="x">(</span><span class="n">w</span><span class="x">)</span>

    <span class="k">if</span> <span class="n">nrm</span> <span class="o">&lt;</span> <span class="n">η</span> <span class="o">*</span> <span class="n">norm</span><span class="x">(</span><span class="n">h</span><span class="x">)</span>
        <span class="n">increment</span> <span class="o">=</span> <span class="n">gemv</span><span class="x">(</span><span class="sc">'T'</span><span class="x">,</span> <span class="n">one</span><span class="x">(</span><span class="n">T</span><span class="x">),</span> <span class="n">V</span><span class="x">,</span> <span class="n">w</span><span class="x">)</span>
        <span class="n">gemv!</span><span class="x">(</span><span class="sc">'N'</span><span class="x">,</span> <span class="o">-</span><span class="n">one</span><span class="x">(</span><span class="n">T</span><span class="x">),</span> <span class="n">V</span><span class="x">,</span> <span class="n">increment</span><span class="x">,</span> <span class="n">one</span><span class="x">(</span><span class="n">T</span><span class="x">),</span> <span class="n">w</span><span class="x">)</span>
        <span class="n">axpy!</span><span class="x">(</span><span class="n">one</span><span class="x">(</span><span class="n">T</span><span class="x">),</span> <span class="n">increment</span><span class="x">,</span> <span class="n">h</span><span class="x">)</span>
        <span class="n">nrm</span> <span class="o">=</span> <span class="n">norm</span><span class="x">(</span><span class="n">w</span><span class="x">)</span>
    <span class="k">end</span>

    <span class="c"># Normalize</span>
    <span class="n">scale!</span><span class="x">(</span><span class="n">w</span><span class="x">,</span> <span class="n">one</span><span class="x">(</span><span class="n">T</span><span class="x">)</span> <span class="o">/</span> <span class="n">nrm</span><span class="x">)</span>

    <span class="n">h</span><span class="x">,</span> <span class="n">nrm</span>
<span class="k">end</span></code></pre></figure> <p>Similarly for MGS:</p> <figure class="highlight"><pre><code class="language-julia" data-lang="julia"><span class="k">function</span><span class="nf"> repeated_modified_gram_schmidt</span><span class="o">!</span><span class="x">{</span><span class="n">T</span><span class="x">}(</span><span class="n">V</span><span class="o">::</span><span class="n">StridedMatrix</span><span class="x">{</span><span class="n">T</span><span class="x">},</span> <span class="n">w</span><span class="o">::</span><span class="n">StridedVector</span><span class="x">{</span><span class="n">T</span><span class="x">};</span> <span class="n">η</span> <span class="o">=</span> <span class="n">one</span><span class="x">(</span><span class="n">T</span><span class="x">)</span> <span class="o">/</span> <span class="n">√2</span><span class="x">)</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">size</span><span class="x">(</span><span class="n">V</span><span class="x">,</span> <span class="mi">2</span><span class="x">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">zeros</span><span class="x">(</span><span class="n">T</span><span class="x">,</span> <span class="n">k</span><span class="x">)</span>

    <span class="n">nrm</span> <span class="o">=</span> <span class="n">norm</span><span class="x">(</span><span class="n">w</span><span class="x">)</span>

    <span class="c"># Orthogonalize</span>
    <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span> <span class="x">:</span> <span class="n">k</span>
        <span class="n">column</span> <span class="o">=</span> <span class="nd">@view</span><span class="x">(</span><span class="n">V</span><span class="x">[:,</span> <span class="n">i</span><span class="x">])</span>
        <span class="n">h</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">=</span> <span class="n">dot</span><span class="x">(</span><span class="n">column</span><span class="x">,</span> <span class="n">w</span><span class="x">)</span>
        <span class="n">axpy!</span><span class="x">(</span><span class="o">-</span><span class="n">h</span><span class="x">[</span><span class="n">i</span><span class="x">],</span> <span class="n">column</span><span class="x">,</span> <span class="n">w</span><span class="x">)</span>
    <span class="k">end</span>

    <span class="k">if</span> <span class="n">norm</span><span class="x">(</span><span class="n">w</span><span class="x">)</span> <span class="o">≤</span> <span class="n">η</span> <span class="o">*</span> <span class="n">nrm</span>
        <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span> <span class="x">:</span> <span class="n">k</span>
            <span class="n">column</span> <span class="o">=</span> <span class="nd">@view</span><span class="x">(</span><span class="n">V</span><span class="x">[:,</span> <span class="n">i</span><span class="x">])</span>
            <span class="n">correction</span> <span class="o">=</span> <span class="n">dot</span><span class="x">(</span><span class="n">column</span><span class="x">,</span> <span class="n">w</span><span class="x">)</span>
            <span class="n">h</span><span class="x">[</span><span class="n">i</span><span class="x">]</span> <span class="o">+=</span> <span class="n">correction</span>
            <span class="n">axpy!</span><span class="x">(</span><span class="o">-</span><span class="n">correction</span><span class="x">,</span> <span class="n">column</span><span class="x">,</span> <span class="n">w</span><span class="x">)</span>
        <span class="k">end</span>

        <span class="n">nrm</span> <span class="o">=</span> <span class="n">norm</span><span class="x">(</span><span class="n">w</span><span class="x">)</span>
    <span class="k">end</span>

    <span class="c"># Normalize</span>
    <span class="n">scale!</span><span class="x">(</span><span class="n">w</span><span class="x">,</span> <span class="n">one</span><span class="x">(</span><span class="n">T</span><span class="x">)</span> <span class="o">/</span> <span class="n">nrm</span><span class="x">)</span>

    <span class="n">h</span><span class="x">,</span> <span class="n">nrm</span>
<span class="k">end</span></code></pre></figure> <p>We benchmark these methods as well:</p> <figure class="highlight"><pre><code class="language-julia" data-lang="julia"><span class="k">function</span><span class="nf"> bench</span><span class="x">(;</span> <span class="n">m</span> <span class="o">=</span> <span class="mi">20</span><span class="x">)</span>
    <span class="n">srand</span><span class="x">(</span><span class="mi">1</span><span class="x">)</span>
    
    <span class="n">suite</span> <span class="o">=</span> <span class="n">BenchmarkGroup</span><span class="x">()</span>
    
    <span class="k">for</span> <span class="n">threads</span> <span class="o">=</span> <span class="x">[</span><span class="mi">1</span><span class="x">,</span> <span class="mi">2</span><span class="x">,</span> <span class="mi">4</span><span class="x">]</span>
        <span class="n">BLAS</span><span class="o">.</span><span class="n">set_num_threads</span><span class="x">(</span><span class="n">threads</span><span class="x">)</span>
        <span class="n">thread_key</span> <span class="o">=</span> <span class="n">string</span><span class="x">(</span><span class="n">threads</span><span class="x">)</span>
        <span class="n">suite</span><span class="x">[</span><span class="n">thread_key</span><span class="x">]</span> <span class="o">=</span> <span class="n">BenchmarkGroup</span><span class="x">()</span>
        <span class="k">for</span> <span class="n">n</span> <span class="o">=</span> <span class="x">[</span><span class="mi">1_000_000</span><span class="x">,</span> <span class="mi">10_000_000</span><span class="x">]</span>
            <span class="n">V</span><span class="x">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">qr</span><span class="x">(</span><span class="n">rand</span><span class="x">(</span><span class="n">n</span><span class="x">,</span> <span class="n">m</span><span class="x">))</span>
            <span class="n">new_vec</span> <span class="o">=</span> <span class="n">rand</span><span class="x">(</span><span class="n">n</span><span class="x">)</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">string</span><span class="x">(</span><span class="n">n</span><span class="x">)</span>
            <span class="n">suite</span><span class="x">[</span><span class="n">thread_key</span><span class="x">][</span><span class="n">key</span><span class="x">]</span> <span class="o">=</span> <span class="n">BenchmarkGroup</span><span class="x">()</span>
            <span class="n">suite</span><span class="x">[</span><span class="n">thread_key</span><span class="x">][</span><span class="n">key</span><span class="x">][</span><span class="s">"rcgs"</span><span class="x">]</span> <span class="o">=</span> <span class="nd">@benchmark</span> <span class="n">repeated_classical_gram_schmidt!</span><span class="x">(</span><span class="o">$</span><span class="n">V</span><span class="x">,</span> <span class="n">a</span><span class="x">)</span> <span class="n">setup</span><span class="o">=</span><span class="x">(</span><span class="n">a</span> <span class="o">=</span> <span class="n">copy</span><span class="x">(</span><span class="o">$</span><span class="n">new_vec</span><span class="x">))</span>
            <span class="n">suite</span><span class="x">[</span><span class="n">thread_key</span><span class="x">][</span><span class="n">key</span><span class="x">][</span><span class="s">"rmgs"</span><span class="x">]</span> <span class="o">=</span> <span class="nd">@benchmark</span> <span class="n">repeated_modified_gram_schmidt!</span><span class="x">(</span><span class="o">$</span><span class="n">V</span><span class="x">,</span> <span class="n">a</span><span class="x">)</span> <span class="n">setup</span><span class="o">=</span><span class="x">(</span><span class="n">a</span> <span class="o">=</span> <span class="n">copy</span><span class="x">(</span><span class="o">$</span><span class="n">new_vec</span><span class="x">))</span>
        <span class="k">end</span>
    <span class="k">end</span>

    <span class="n">suite</span>
<span class="k">end</span></code></pre></figure> <p>and their results are:</p> <figure class="highlight"><pre><code class="language-text" data-lang="text">  "1" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
          "1000000" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
                  "rcgs" =&gt; Trial(37.474 ms)
                  "rmgs" =&gt; Trial(79.268 ms)
          "10000000" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
                  "rcgs" =&gt; Trial(393.802 ms)
                  "rmgs" =&gt; Trial(829.219 ms)
  "2" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
          "1000000" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
                  "rcgs" =&gt; Trial(32.237 ms)
                  "rmgs" =&gt; Trial(72.151 ms)
          "10000000" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
                  "rcgs" =&gt; Trial(331.603 ms)
                  "rmgs" =&gt; Trial(787.374 ms)
  "4" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
          "1000000" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
                  "rcgs" =&gt; Trial(31.030 ms)
                  "rmgs" =&gt; Trial(69.855 ms)
          "10000000" =&gt; 2-element BenchmarkTools.BenchmarkGroup:
                  "rcgs" =&gt; Trial(323.154 ms)
                  "rmgs" =&gt; Trial(785.251 ms)</code></pre></figure> <p>The good news is that repeated classical Gram-Schmidt is still faster than modified Gram-Schmidt without repetition.</p> <h2 id="conclusion">Conclusion</h2> <p>If orthogonality is so important that repeated orthogonalization is necessary, then repeated classical Gram-Schmidt seems a good candidate. Even if repeated orthogonalization is not a necessity, repeated classical Gram-Schmidt can even be faster than modified Gram-Schmidt without repetition.</p> <p>Note that this implies that the orthonormal basis <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.22222em;">V</span></span></span></span> is indeed best represented as a <code class="highlighter-rouge">Matrix</code> rather than a <code class="highlighter-rouge">Vector</code> of <code class="highlighter-rouge">Vector</code>s.</p> <h3 id="remark">Remark</h3> <p>In the benchmarks above I normalize a vector by first computing <code class="highlighter-rouge">t = 1 / norm(w)</code> and only then computing <code class="highlighter-rouge">w *= t</code>. The good thing is that multiplication is a lot faster than division, but the downside is that we round numbers twice. I don’t know if the latter has significant consequences for orthogonality.</p> </div> <div class="article-share"> <a href="" title="Share on Twitter" onclick="window.open('https://twitter.com/home?status=Orthogonalization performance - http://stoppels.blog/posts/orthogonalization-performance ', 'newwindow', 'width=500, height=225'); return false;" data-turbolinks="false"> <svg enable-background="new 0 0 128 128" width="15px" version="1.1" viewBox="0 0 128 128" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g id="_x37__stroke"><g id="Twitter"><rect clip-rule="evenodd" fill="none" fill-rule="evenodd" height="128" width="128"/><path clip-rule="evenodd" d="M128,23.294 c-4.703,2.142-9.767,3.59-15.079,4.237c5.424-3.328,9.587-8.606,11.548-14.892c-5.079,3.082-10.691,5.324-16.687,6.526 c-4.778-5.231-11.608-8.498-19.166-8.498c-14.493,0-26.251,12.057-26.251,26.927c0,2.111,0.225,4.16,0.676,6.133 C41.217,42.601,21.871,31.892,8.91,15.582c-2.261,3.991-3.554,8.621-3.554,13.552c0,9.338,4.636,17.581,11.683,22.412 c-4.297-0.131-8.355-1.356-11.901-3.359v0.331c0,13.051,9.053,23.937,21.074,26.403c-2.201,0.632-4.523,0.948-6.92,0.948 c-1.69,0-3.343-0.162-4.944-0.478c3.343,10.694,13.035,18.483,24.53,18.691c-8.986,7.227-20.315,11.533-32.614,11.533 c-2.119,0-4.215-0.123-6.266-0.37c11.623,7.627,25.432,12.088,40.255,12.088c48.309,0,74.717-41.026,74.717-76.612 c0-1.171-0.023-2.342-0.068-3.49C120.036,33.433,124.491,28.695,128,23.294" fill-rule="evenodd" id="Twitter_1_"/></g></g></svg> </a> <a href="" title="Share on Facebook" onclick="window.open('https://www.facebook.com/sharer/sharer.php?u=http://stoppels.blog/posts/orthogonalization-performance', 'newwindow', 'width=500, height=500'); return false;" data-turbolinks="false"> <svg enable-background="new 0 0 128 128" width="15px" version="1.1" viewBox="0 0 128 128" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g id="_x31__stroke"><g id="Facebook_1_"><rect fill="none" height="128" width="128"/><path clip-rule="evenodd" d="M68.369,128H7.065C3.162,128,0,124.836,0,120.935 V7.065C0,3.162,3.162,0,7.065,0h113.871C124.837,0,128,3.162,128,7.065v113.87c0,3.902-3.163,7.065-7.064,7.065H88.318V78.431 h16.638l2.491-19.318H88.318V46.78c0-5.593,1.553-9.404,9.573-9.404l10.229-0.004V20.094c-1.769-0.235-7.841-0.761-14.906-0.761 c-14.749,0-24.846,9.003-24.846,25.535v14.246H51.688v19.318h16.681V128z" fill-rule="evenodd" id="Facebook"/></g></g></svg> </a> <a href="" title="Share on Google+" onclick="window.open('https://plus.google.com/share?url=http://stoppels.blog/posts/orthogonalization-performance', 'newwindow', 'width=550, height=400'); return false;" data-turbolinks="false"> <svg enable-background="new 0 0 128 128" version="1.1" viewBox="0 0 128 128" width="20px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g id="_x35__stroke"><g id="Google_Plus"><rect clip-rule="evenodd" fill="none" fill-rule="evenodd" height="128" width="128"/><path clip-rule="evenodd" d="M40.654,55.935v16.13 c0,0,15.619-0.021,21.979-0.021C59.189,82.5,53.834,88.194,40.654,88.194c-13.338,0-23.748-10.832-23.748-24.194 s10.41-24.194,23.748-24.194c7.052,0,11.607,2.483,15.784,5.944c3.344-3.35,3.065-3.828,11.573-11.877 c-7.222-6.586-16.822-10.6-27.357-10.6C18.201,23.273,0,41.507,0,64c0,22.493,18.201,40.727,40.654,40.727 c33.561,0,41.763-29.275,39.044-48.792H40.654z M113.912,56.742V42.628h-10.063v14.113H89.358v10.081h14.491v14.517h10.063V66.823 H128V56.742H113.912z" fill-rule="evenodd" id="Google_Plus_1_"/></g></g></svg> </a> </div> </article> <footer class="footer"> <p>Copyright © Harmen Stoppels 2016 - 2017</p> </footer> </div> </div> </main> <script>
window.ga=function(){ga.q.push(arguments)};ga.q=[];ga.l=+new Date;
ga('create','UA-93471447-1','auto');ga('send','pageview')
</script> <script src="https://www.google-analytics.com/analytics.js" async defer></script> </body> </html>